#!/usr/bin/env python

import argparse
import cStringIO
import csv
import logging

import tacl


def main ():
    parser = generate_parser()
    args = parser.parse_args()
    configure_logging(args.verbose)
    args.func(args)

def add_common_arguments (parser):
    """Adds common arguments for all parsers."""
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='display verbose debugging information')

def add_ngram_arguments (parser):
    """Adds common arguments for the n-gram subcommands to `subparser`."""
    parser.add_argument('db', metavar='DATABASE', help='database file')
    parser.add_argument('corpus', help='path to corpus')
    parser.add_argument('min_size', metavar='MINIMUM_SIZE', type=int,
                        help='minimum size of n-gram to generate')
    parser.add_argument('max_size', metavar='MAXIMUM_SIZE', type=int,
                        help='maximum size of n-gram to generate')

def add_result_arguments (parser):
    parser.add_argument('-o', '--occurrences', default=2, type=int,
                        help='minimum occurrences required to list')
    parser.add_argument('-t', '--text', action='store_true',
                        help='output report on individual text frequencies')
    parser.add_argument('catalogue', help='path to catalogue',
                        metavar='CATALOGUE')

def configure_logging (verbose):
    logger = logging.getLogger('tacl')
    log_level = logging.WARN
    if verbose:
        log_level = logging.DEBUG
    logging.basicConfig(format='%(levelname)s: %(message)s', level=log_level)

def generate_parser ():
    parser = argparse.ArgumentParser(description='Analyse the text of corpora in various simple ways.')
    subparsers = parser.add_subparsers(title='subcommands')
    generate_catalogue_subparser(subparsers)
    generate_diff_subparser(subparsers)
    generate_intersect_subparser(subparsers)
    generate_ngrams_subparser(subparsers)
    generate_strip_subparser(subparsers)
    return parser

def generate_catalogue (args):
    catalogue = tacl.Catalogue()
    catalogue.generate(args.corpus, args.label)
    catalogue.save(args.catalogue)

def generate_catalogue_subparser (subparsers):
    parser = subparsers.add_parser(
        'catalogue', description='Generate a catalogue file',
        help='generate a catalogue file')
    add_common_arguments(parser)
    parser.set_defaults(func=generate_catalogue)
    parser.add_argument('corpus', help='path to corpus')
    parser.add_argument('catalogue', help='path to catalogue file')
    parser.add_argument('-l', '--label', help='label to use for all texts',
                        default='')

def generate_diff_subparser (subparsers):
    parser = subparsers.add_parser(
        'diff', description='List n-grams unique to each sub-corpus.',
        help='list n-grams in one corpus but not the other')
    parser.set_defaults(func=ngram_diff)
    add_common_arguments(parser)
    add_ngram_arguments(parser)
    add_result_arguments(parser)

def generate_intersect_subparser (subparsers):
    parser = subparsers.add_parser(
        'intersect', description='List n-grams common to all sub-corpora.',
        help='list n-grams common to all sub-corpora')
    parser.set_defaults(func=ngram_intersection)
    add_common_arguments(parser)
    add_ngram_arguments(parser)
    add_result_arguments(parser)

def generate_ngrams (args):
    corpus = get_corpus(args)
    corpus.generate_ngrams(args.min_size, args.max_size)

def generate_ngrams_subparser (subparsers):
    parser = subparsers.add_parser(
        'ngrams', description='Generate n-grams from a corpus.',
        help='generate n-grams from a corpus')
    parser.set_defaults(func=generate_ngrams)
    add_common_arguments(parser)
    add_ngram_arguments(parser)

def generate_strip_subparser (subparsers):
    parser = subparsers.add_parser('strip', help='preprocess a corpus by stripping unwanted material from each text', description='Preprocess a corpus by stripping unwanted material from each text.')
    parser.set_defaults(func=strip_texts)
    add_common_arguments(parser)
    parser.add_argument('input', metavar='INPUT',
                        help='directory containing files to strip')
    parser.add_argument('output', metavar='OUTPUT',
                        help='directory to output stripped files to')

def get_corpus (args):
    manager = tacl.DBManager(args.db)
    corpus = tacl.Corpus(args.corpus, manager)
    return corpus

def get_catalogue (args):
    catalogue = tacl.Catalogue()
    catalogue.load(args.catalogue)
    return catalogue

def ngram_diff (args):
    corpus = get_corpus(args)
    catalogue = get_catalogue(args)
    data = corpus.diff(catalogue, args.min_size, args.max_size,
                       args.occurrences)
    if args.text:
        output_text_frequencies(data)
    else:
        output_csv(data)

def ngram_intersection (args):
    corpus = get_corpus(args)
    catalogue = get_catalogue(args)
    ngrams = corpus.intersection(catalogue, args.min_size, args.max_size,
                                 args.occurrences)
    if args.text:
        output_text_frequencies(ngrams)
    else:
        output_csv(ngrams)

def output_csv (data):
    """Output `data` in CSV format (ngram, total frequency).

    :param data: n-gram data to output
    :type data: `list` of `sqlite3.Row`

    """
    output = cStringIO.StringIO()
    writer = csv.writer(output)
    for row in data:
        line = (row['ngram'].encode('utf-8'), row['count'], row['label'])
        writer.writerow(line)
    print(output.getvalue())

def output_text_frequencies (ngrams):
    """Output `data` as a report with individual text frequencies.

    :param data: n-gram data to output
    :type data: `list` of `sqlite3.Row`

    """
    for row in data:
        print('%s, %d' % (unicode(ngram).encode('utf-8'), total))
        for text, frequency in ngram.text_counts().items():
            print('   %d: %s' % (frequency, text.path))

def strip_texts (args):
    stripper = tacl.Stripper(args.input, args.output)
    stripper.strip_files()


if __name__ == '__main__':
    main()
